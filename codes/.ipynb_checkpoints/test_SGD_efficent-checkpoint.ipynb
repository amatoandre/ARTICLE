{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472ff886",
   "metadata": {},
   "source": [
    "# SGD with Mini Batch for Kuramoto-Shinomoto-Sakaguchi MV-SDE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd98ef24",
   "metadata": {},
   "source": [
    "First of all we importiamo all the pacchetti to use the mathematical function in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e25496e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from numpy import linalg as LA\n",
    "from numpy import mean\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6967e6a0",
   "metadata": {},
   "source": [
    "Scriviamo la MV-SDE relativa al modello di Kuramoto-Shinomoto-Sakaguchi, ovvero:\n",
    "\n",
    "$$ dX_t = \\left( \\mathbb{E}[sen(X_t)] cos(X_t) - \\mathbb{E}[cos(X_t)] sen(X_t) \\right) dt + \\sigma dW_t , \\ \\ \\ X_0=x_0. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d08153",
   "metadata": {},
   "source": [
    "Da questa equazione differenziale si evince che:\n",
    "* K = 3, d = 1 e q = 1,\n",
    "* $\\varphi(x)=(1, senx, cosx)$, \n",
    "* $\\alpha(t,x)=(0, cosx, -senx)^T$, \n",
    "* $\\beta(t,x)=(\\sigma, 0 , 0)^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b2833",
   "metadata": {},
   "source": [
    "## Metodo di Eulero - Monte Carlo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c7bcc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(sigma, T, N, M, X0):\n",
    "    h = T / N\n",
    "    X = X0 * np.ones(M)\n",
    "    gamma1 = np.zeros(N+1)\n",
    "    gamma2 = np.zeros(N+1)\n",
    "    gamma1[0] = mean(np.sin(X))\n",
    "    gamma2[0] = mean(np.cos(X))\n",
    "    \n",
    "    for i in range(N):\n",
    "        W = np.random.normal(0, 1, M) \n",
    "        X = X + (gamma1[i] * np.cos(X) - gamma2[i] * np.sin(X)) * h + sigma * math.sqrt(h) * W\n",
    "        gamma1[i+1] = mean(np.sin(X))\n",
    "        gamma2[i+1] = mean(np.cos(X))\n",
    "    \n",
    "    return X, gamma1, gamma2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7057b80b",
   "metadata": {},
   "source": [
    "## Metodo di Discesa del Gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ff9fa5",
   "metadata": {},
   "source": [
    "### Metodo di Eulero per la Simulazione di $Z(\\xi , W)$ e di $\\left( Z^a(\\tilde{\\xi} , \\tilde{W}), \\partial_{a_{h,j}} Z^a(\\tilde{\\xi} , \\tilde{W}) \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7af779d",
   "metadata": {},
   "source": [
    "Definiamo le due funzioni che ci permettono di simulare $Z(\\xi , W)$ e $\\left( Z^a(\\tilde{\\xi} , \\tilde{W}), \\partial_{a_{h,j}} Z^a(\\tilde{\\xi} , \\tilde{W}) \\right)$, ovvero le soluzioni del sistema dato dalle seguenti equazioni differenziali:\n",
    "\n",
    "$$ dZ_t = \\textbf{h} \\left((\\mathcal{L}a)(t)\\right) \\left( \\alpha(t, Z_t)dt + \\beta(t, Z_t)dW_t\\right), \\ \\ \\ Z_0 = \\xi.$$\n",
    "\n",
    "$$ dY^{j,k}_t = g_j(t) \\nabla \\textbf{h}_k \\left((\\mathcal{L}a)(t)\\right) \\left( \\alpha(t, Z_t)dt + \\beta(t, Z_t)dW_t\\right) + \\sum_{i=0}^d Y^{j,k,i}_t  \\textbf{h} \\left((\\mathcal{L}a)(t)\\right) \\left( \\partial_{z_i}\\alpha(t, Z_t)dt + \\partial_{z_i}\\beta(t, Z_t)dW_t\\right), \\ \\ \\ \\ Y^{j,k}_0 = 0,$$\n",
    "\n",
    "per $j = 0, \\cdots , n$ e $k = 1, \\cdots, K$.\n",
    "\n",
    "Ricordiamo che la prima equazione corrisponde alla $(13)$ del articolo e alla $(1.6)$ della mia bozza di tesi, mentre la seconda equazione corrisponde alla $(14)$ dell'articolo e alla $(1.8)$ della mia bozza di tesi. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b13a353",
   "metadata": {},
   "source": [
    "Questa funzione serve per creare la base dello spazio dei polinomi. Prende in input la dimensione $n$, il tempo $t$ nella quale i vettori della base devono essere calcolati e la tipologia di base scelta. Restituisce un vettore $n+1$ dimensionale che rappresenta gli elementi della base calcolati in $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87335224",
   "metadata": {},
   "source": [
    "* base canonica:   $g_i(t):= t^i$ con nodi equidistanti;\n",
    "* base di Lagrange: $g_i(t):=\\prod_{j \\leq n \\ e  \\ j\\neq n} \\left( \\frac{t - t_j}{t_i - t_j} \\right) $ con nodi di Chebyshev: $\\frac{a+b}{2} + \\frac{b-a}{2} cos \\left( \\frac{2k + 1}{2n +2} \\pi \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ded2911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base(T, N, n, X0, tipo):\n",
    "    g = np.ones(n+1)\n",
    "    cc = np.linspace(0, T, N+1)\n",
    "    \n",
    "    if tipo == 'canonica':\n",
    "        g = np.array([ cc ** i for i in range(n+1)]) \n",
    "        \n",
    "        a1_0 = np.sin(X0) * g[:,0]\n",
    "        a2_0 = np.cos(X0) * g[:,0]\n",
    "        \n",
    "        return a1_0, a2_0, g\n",
    "    \n",
    "    elif tipo == 'lagrange':\n",
    "        l = [(0 + T)/2 + (T - 0)/2 * np.cos(((2 * i + 1)/ (2 * n + 2)) * math.pi) for i in range(n+1)]\n",
    "        \n",
    "        g = np.array([math.prod([((cc - l[j]) / (l[i] - l[j])) for j in range(n+1) if j!=i]) for i in range(n+1)])\n",
    "        \n",
    "        a1_0 = np.sin(X0) * np.ones(n+1) \n",
    "        a2_0 = np.cos(X0) * np.ones(n+1) \n",
    "\n",
    "        return a1_0, a2_0, g \n",
    "        \n",
    "    \n",
    "    else:\n",
    "        return 'err'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2808e4bc",
   "metadata": {},
   "source": [
    "In questo algoritmo semplificato le mappe $\\textbf{h}$ e $ H $ sono prese rispettivamente come l'identià e la funzione nulla. Riprendendo i valori delle funzioni dei coefficienti per la MV-SDE relativa al modello di Kuramoto-Shninomoto-Sakaguchi si ottiene che nello specifico le equazioni diventano:\n",
    "\n",
    "$$ dZ_t = \\left( (\\mathcal{L}a)_1(t) cos(Z_t) - (\\mathcal{L}a)_2(t) sen(Z_t) \\right) dt + \\sigma dW_t, \\ \\ \\ Z_0 = X_0. $$\n",
    "\n",
    "$$ dY^{j,1}_t = \\left( g_j(t) cos(Z_t) - Y^{j,1}_t \\left( (\\mathcal{L}a)_1(t)sen(Z_t) + (\\mathcal{L}a)_2(t)cos(Z_t)\\right) \\right)dt, \\ \\ \\ Y^{j,1}_0 = 0,$$\n",
    "\n",
    "$$ dY^{j,2}_t = \\left( -g_j(t) sen(Z_t) - Y^{j,2}_t \\left( (\\mathcal{L}a)_1(t)sen(Z_t) + (\\mathcal{L}a)_2(t)cos(Z_t)\\right) \\right)dt, \\ \\ \\ Y^{j,2}_0 = 0,$$\n",
    "per $j = 0, \\cdots , n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca80ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eulero(a1, a2, sigma, n, N, M, Z0, h, g):\n",
    "    \n",
    "    X = Z0 * np.ones((N+1, M))\n",
    "    Z = Z0 * np.ones((N+1, M))\n",
    "    Y1 = np.zeros((N+1, n+1, M))\n",
    "    Y2 = np.zeros((N+1, n+1, M))\n",
    "    \n",
    "    for i in range(N):\n",
    "        c1 = np.dot(a1, g[:,i])\n",
    "        c2 = np.dot(a2, g[:,i])\n",
    "        \n",
    "        W = np.random.normal(0, 1, (2, M)) \n",
    "    \n",
    "        X[i+1] = X[i] + (c1 * np.cos(X[i]) - c2 * np.sin(X[i])) * h + sigma * math.sqrt(h) * W[0] \n",
    "\n",
    "        Y1[i+1] = Y1[i] + ((g[:,i] * np.ones((M, 1))).transpose() * np.cos(Z[i]) - Y1[i] * (c1 * np.sin(Z[i]) + c2 * np.cos(Z[i]))) * h\n",
    "        Y2[i+1] = Y2[i] + ((-g[:,i] * np.ones((M, 1))).transpose() * np.sin(Z[i]) - Y2[i] * (c1 * np.sin(Z[i]) + c2 * np.cos(Z[i]))) * h\n",
    "\n",
    "        Z[i+1] = Z[i] + (c1 * np.cos(Z[i]) - c2 * np.sin(Z[i])) * h + sigma * math.sqrt(h) * W[1]\n",
    "        \n",
    "    \n",
    "    return X, Z, Y1, Y2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7bac12",
   "metadata": {},
   "source": [
    "### Metodo di Discesa "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da5da8f",
   "metadata": {},
   "source": [
    "In questa sezione ci sono le due funzioni cardine del codice. La prima serve a calcolare la realizzazione del gradiente per la discesa stocastica, ovvero la funzione $v$ descritta nella (17) dell'articolo. In generale la scrittura di $v$, componente per componente, è la seguente:\n",
    "\n",
    "$$v_{j,k}(a; \\xi, W; \\tilde{\\xi}, \\tilde{W}) = 2 \\int_0^T \\langle \\varphi (Z^a_t(\\xi,W)) - \\textbf{h} ((\\mathcal{L}a)(t)), \\nabla_x \\varphi (Z^a_t(\\tilde{\\xi}, \\tilde{W})) Y_t^{a;j,k}(\\tilde{\\xi}, \\tilde{W}) - \\partial_{a_{j,k}}\\textbf{h}((\\mathcal{L}a)(t))\\rangle dt, $$ \n",
    "con $j = 0, \\cdots , n$ e $k = 1, \\cdots, K$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de3e8a5",
   "metadata": {},
   "source": [
    "Come nei casi precedenti scriviamo questa e quazione nel caso specifico del nostro algoritmo. Avendo suddiviso il tempo in N steps temporali, approssimiamo l'integrale con una sommatoria.\n",
    "\n",
    "$$v_{j,1}(a; W; \\tilde{W}) = 2 h \\sum_{t=0}^{N} \\left[ \\left( sen(Z^a_t(W)) - (\\mathcal{L}a)_1(t) \\right) \\cdot \\left( cos(Z^a_t(\\tilde{W})) Y_t^{a;j,1}(\\tilde{W}) - g_j(t) \\right) + \\left( cos(Z^a_t(W)) - (\\mathcal{L}a)_2(t) \\right) \\cdot \\left( -sen(Z^a_t(\\tilde{W})) Y_t^{a;j,1}(\\tilde{W}) \\right)\\right], $$ \n",
    "\n",
    "$$v_{j,2}(a; W; \\tilde{W}) = 2 h \\sum_{t=0}^{N} \\left[ \\left( sen(Z^a_t(W)) - (\\mathcal{L}a)_1(t) \\right) \\cdot \\left( cos(Z^a_t(\\tilde{W})) Y_t^{a;j,2}(\\tilde{W}) \\right) + \\left( cos(Z^a_t(W)) - (\\mathcal{L}a)_2(t) \\right) \\cdot \\left( -sen(Z^a_t(\\tilde{W})) Y_t^{a;j,2}(\\tilde{W}) - g_j(t) \\right)\\right], $$  \n",
    "con $j = 0, \\cdots , n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e9a7f",
   "metadata": {},
   "source": [
    "Notiamo che prima di restituire il valore $v$ questa fuzione fa una media. Esso serve nel caso $M>1$ in cui sfruttiamo molteplici simulzioni del browniano per aver una miglior stima di $v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecde5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discesa_stocastica_del_gradiente(a1_0, a2_0, n, r0, rho, sigma, N, M, X0, eps, h, g, gamma1, gamma2, l):\n",
    "    a1 = a1_0 \n",
    "    a2 = a2_0\n",
    "\n",
    "    norma1 = LA.norm(gamma1)\n",
    "    norma2 = LA.norm(gamma2)\n",
    "    \n",
    "    for m in range(50000):\n",
    "        \n",
    "        if (m % l == 0):\n",
    "            if ( ((LA.norm(np.dot(a1,g) - gamma1)/ norma1) < eps) and ((LA.norm(np.dot(a2,g) - gamma2)/ norma2) < eps) ):\n",
    "                break\n",
    "            \n",
    "        eta = r0 / ((m + 1) ** rho) \n",
    "        \n",
    "        Z, Ztilde, Y1tilde, Y2tilde = eulero(a1, a2, sigma, n, N, M, X0, h, g)\n",
    "        \n",
    "        \n",
    "        v1 = np.zeros(n+1)\n",
    "        v2 = np.zeros(n+1)\n",
    "        \n",
    "        for j in range(n+1): \n",
    "\n",
    "            v1[j] = mean( 2 * h * sum( (np.sin(Z) - (np.dot(a1,g) * np.ones((M, 1))).transpose()) \\\n",
    "                                      * (np.cos(Ztilde) * Y1tilde[:,j] - (g[j,:] * np.ones((M, 1))).transpose()) \\\n",
    "                                      + (np.cos(Z) - (np.dot(a2,g) * np.ones((M, 1))).transpose()) \\\n",
    "                                      * (-np.sin(Ztilde) * Y1tilde[:,j]) ) ) \n",
    "        \n",
    "            v2[j] = mean( 2 * h * sum( (np.sin(Z) - (np.dot(a1,g) * np.ones((M, 1))).transpose()) \\\n",
    "                                      * (np.cos(Ztilde) * Y2tilde[:,j]) \\\n",
    "                                      + (np.cos(Z) - (np.dot(a2,g) * np.ones((M, 1))).transpose()) \\\n",
    "                                      * (-np.sin(Ztilde) * Y2tilde[:,j] - (g[j,:] * np.ones((M, 1))).transpose()) ) )\n",
    "        \n",
    "        a1 = a1 - eta * v1\n",
    "        a2 = a2 - eta * v2\n",
    "        \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e00b41",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c04ab48",
   "metadata": {},
   "source": [
    "Concludiamo riportando il main che richiama le funzioni sopra definite. Ricordiamo a cosa corrisponderanno i valori che daremo in input alle funzioni che richiameremo:\n",
    "* N : numero di iterazioni (steps temporali),\n",
    "* M : numero di simulazioni in ogni istante,\n",
    "* T : istante finale,\n",
    "* $\\mu$ : funzione di Drift,\n",
    "* $\\sigma$ : funzione di Diffuzione,\n",
    "* h : step temporale,\n",
    "* $X_0$ : dato iniziale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40527834",
   "metadata": {},
   "source": [
    "Richiameremo inoltre:\n",
    "* n: dimensione dello spazio dei polinomi,\n",
    "* $a_0$: valore iniziale del vettore del metodo SGD. Ora è semplificata, poi ci mettiamo lo sviluppo di Taylor di Kolmogorov di gamma1+gamma2,\n",
    "* $r_0$ e $\\rho$: servono per i learning rates e devono essere  $r_0 \\in (0, +\\infty)$ e $\\frac{1}{2} < \\rho \\leq 1$ ,\n",
    "* m: num di step per il mtodo SGD,\n",
    "* M: mini batch tra SGD e GD,\n",
    "* $\\epsilon$: tolleranza errore relativo dell' 1%,\n",
    "* k: numero di iterazioni successive che devono essere minori di $\\epsilon$ per fermare il ciclo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e9e0122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo di esecuzione Eulero - Monte Carlo:  38.46875\n",
      " \n",
      "fatto n = 3\n",
      "fatto n = 4\n",
      "fatto n = 5\n",
      "fatto n = 6\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Parametri variabili\n",
    "    \n",
    "    T = 2  # 0.5, 1, 2, 4\n",
    "    nnn = [3, 4, 5, 6]  \n",
    "    M = [1, 10, 100, 1000, 10000]  #ricorda per gli ultimi due di togliere m % 10\n",
    "    \n",
    "\n",
    "    \n",
    "    # Parametri fissi\n",
    "    \n",
    "    sigma = 0.5\n",
    "    N = 200\n",
    "    X0 = 0.5\n",
    "    \n",
    "    N1 = 200   # 1000\n",
    "    M1 = 1000000\n",
    "    \n",
    "    h = T / N  \n",
    "    r0 = [1, 5]\n",
    "    rho = [0.6, 0.7, 0.8, 0.9]\n",
    "    eps = 0.01\n",
    "    l = [10, 10, 10, 1, 1]\n",
    "    ripetizioni = 10 \n",
    "    tipo = 'lagrange'\n",
    "\n",
    "        \n",
    "    # Eulero Monte Carlo\n",
    "    \n",
    "    start = time.process_time()   # parte il cronometro\n",
    "    X, Gamma1, Gamma2 = monte_carlo(sigma, T, N1, M1, X0)\n",
    "    end = time.process_time()   # si ferma il cronometro\n",
    "    \n",
    "    print(\"Tempo di esecuzione Eulero - Monte Carlo: \", end - start)\n",
    "    print(\" \")\n",
    "    \n",
    "    gamma1 = np.array(Gamma1)\n",
    "    gamma2 = np.array(Gamma2)\n",
    "    \n",
    "    # gamma1 = np.array([Gamma1[i] for i in range(0, len(Gamma1), int(N1/N))])\n",
    "    # gamma2 = np.array([Gamma2[i] for i in range(0, len(Gamma2), int(N1/N))])\n",
    "\n",
    "    \n",
    "    for n in nnn:\n",
    "        \n",
    "        # Discesa del Gradiente\n",
    "        \n",
    "        a1_0, a2_0, g = base(T, N, n, X0, tipo)\n",
    "        m = np.zeros((len(rho), len(r0)*3+1))\n",
    "        m[:,0] = rho\n",
    "        \n",
    "        with open(\"tempi n = \"+str(n)+\".txt\", \"w\") as f:\n",
    "            \n",
    "            for p in range(len(M)):\n",
    "                f.write(\"Numero m di step per avere convergenza con M = \"+str(M[p])+\" :\")\n",
    "                f.write(\"\\n\")\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "                for i in range(len(r0)):\n",
    "                    for j in range(len(rho)):\n",
    "\n",
    "                        start = time.process_time()   # parte il cronometro \n",
    "                        mm = [discesa_stocastica_del_gradiente(a1_0, a2_0, n,r0[i], rho[j], sigma, N, M[p], X0, eps, h, g, gamma1, gamma2, l[p]) for k in range(ripetizioni)] \n",
    "                        m[j,3*i+1:3*i+4] = [min(mm), max(mm), mean(mm)]\n",
    "                        end = time.process_time()   # si ferma il cronometro \n",
    "\n",
    "                        f.write(\"Tempo di esecuzione con r0=\"+str(r0[i])+\" e rho=\"+str(rho[j])+\": \"+ str((end - start)/ripetizioni))\n",
    "                        f.write(\"\\n\")\n",
    "\n",
    "                f.write(\"\\n\")\n",
    "                f.write(tabulate(m[:,:], headers=[\" rho \\ r0\", \"1 (min)\", \"1 (max)\", \"1 (medio)\", \"5 (min)\", \"5 (max)\", \"5 (medio)\"]))\n",
    "                f.write(\"\\n\")\n",
    "                f.write(\"\\n\")\n",
    "        \n",
    "        print(\"fatto n = \"+str(n))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c408ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1f4dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
