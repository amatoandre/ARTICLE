{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472ff886",
   "metadata": {},
   "source": [
    "# SGD with Mini Batch for Convolution Type MV-SDE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd98ef24",
   "metadata": {},
   "source": [
    "First of all, we import all the packages needed to use the mathematical functions of python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e25496e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from numpy import linalg as LA\n",
    "from numpy import mean\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6967e6a0",
   "metadata": {},
   "source": [
    "The original MV-SDE is given as :\n",
    "\n",
    "$$\\textrm{d} X_t = \\left. \\mathbb{E}\\left[\\exp\\left(-\\cfrac{(X_t- x)^2}{2}\\right)\\right]\\right|_{x=X_t}  \\textrm{d} t +  \\sigma \\textrm{d} W_t, \\quad X_0 = \\mathcal{N}_{(0,1)}.$$\n",
    "\n",
    "Note that above is of the form of equation (1.1) in Belomestny-Schoenmakers 2018. In paticular, we are interested in the approximation:\n",
    "$$ \\textrm{d} X_t = \\sum^K_{k=0}\\gamma_k(t) \\alpha_k(X_t) \\textrm{d} t +  \\sigma \\textrm{d} W_t, \\quad X_0 = \\mathcal{N}_{(0,1)}. $$\n",
    "The above is of of the form of equation (2.3) in Belomestny-Schoenmakers 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d08153",
   "metadata": {},
   "source": [
    "In the MV-SDE we see that:\n",
    "\n",
    "* K = fixed parameter + 1, d = 1 e q = 1;\n",
    "* $ \\varphi_k(x) = \\overline{H}_k(x) \\mathrm{e}^{-x^2/2}, \\hspace{1cm} \\gamma_k(t) = \\mathbb {E}[\\varphi_k(X_t)], \\hspace{1cm} \\mbox{for } k = 0, \\cdots, K$; \n",
    "* $ \\alpha_k(x) = \\pi^{1/4}\\Bigl( \\frac{1}{2}\\Bigr)^{k/2} \\frac{x^k}{\\sqrt{k!}} \\mathrm{e}^{-x^2/4}, \\hspace{1cm} \\mbox{for } k = 0, \\cdots, K$; \n",
    "* $ \\beta(x)=(\\sigma, 0, \\cdots, 0)^T $.\n",
    "\n",
    "Also:\n",
    "\n",
    "$$ \\alpha'_k(x) = -\\pi^{1/4}\\Bigl( \\frac{1}{2}\\Bigr)^{k/2+1} \\frac{x^{k-1}  (x^2-2k) }{\\sqrt{k!}} \\mathrm{e}^{-x^2/4}, \\hspace{1cm} \\mbox{for } k = 0, \\cdots K. $$ \n",
    "\n",
    "In the above, $\\overline{H}_k(x)$ are the normalised Hermite polynomials:\n",
    "\n",
    "$$ \\overline{H}_k(x) = c_k (-1)^k \\mathrm{e}^{x^2} \\frac{\\mathrm{d}^k}{\\mathrm{d} x^k} \\bigl( \\mathrm{e}^{-x^2}\\bigr) =  c_k \\mathrm{e}^{x^2/2} \\left( x - \\frac{\\mathrm{d}}{\\mathrm{d} x} \\right) ^k \\mathrm{e}^{-x^2/2}, \\hspace{1cm} c_k = \\bigl(2^k k! \\sqrt{\\pi} \\bigr)^{-1/2}. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b2833",
   "metadata": {},
   "source": [
    "## Euler - Monte Carlo Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1731c353",
   "metadata": {},
   "source": [
    "Before showing the function that applies the Euler - Monte Carlo method, let us look at a couple of recursive functions that will be called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d9040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    if n == 1:\n",
    "        return [1, 1]\n",
    "    else:\n",
    "        return factorial(n-1)+[math.factorial(n)]\n",
    "    \n",
    "def exponential(K, x):\n",
    "    if K == 1:\n",
    "        return [x**0, x]\n",
    "    else:\n",
    "        return exponential(K-1,x)+[x**K] \n",
    "    \n",
    "def exponential1(K, x):\n",
    "    if K == 1:\n",
    "        return [x, x**2 - 2]  \n",
    "    else:\n",
    "        return exponential1(K-1, x)+[x**(K-1) * (x**2 - 2*K)]\n",
    "    \n",
    "def alpha(K, M, x, f):\n",
    "    return ( (( math.pi**(1/4) * (1/2)**(np.array(range(K+1))/2) ) * np.ones((M,1)) ).transpose() \\\n",
    "            * np.array(exponential(K, x)) \\\n",
    "            * ( ( np.array(f)**(-1/2) ) * np.ones((M,1)) ).transpose() \\\n",
    "            * np.exp(-(x**2)/4) * np.ones((K+1,1)) ) \n",
    "        \n",
    "def alpha1(K, M, x, f):\n",
    "    return ( - (( math.pi**(1/4) * (1/2)**(np.array(range(K+1))/2+1) ) * np.ones((M,1)) ).transpose() \\\n",
    "            * np.array(exponential1(K, x)) \\\n",
    "            * (( np.array(f)**(-1/2) ) * np.ones((M,1)) ).transpose() \\\n",
    "            * np.exp(-(x**2)/4) * np.ones((K+1,1)) ) \n",
    "        \n",
    "def H(K, x, f):\n",
    "    const = ( (2**K)**(-(1/2)) ) * ( f[K]**(-(1/2)) ) * ( (math.pi)**(-(1/4)) ) \n",
    "    if K == 1:\n",
    "            return [( math.pi )**(-(1/4)) * np.ones((np.shape(x))), const * x]\n",
    "    return H(K-1, x, f)+[const * (scipy.special.hermite(K, monic=False)(x))]\n",
    "\n",
    "def phi1(K, x, f):\n",
    "    const = ( (2**K)**(-(1/2)) ) * ( f[K]**(-(1/2)) ) * ( (math.pi)**(-(1/4)) )\n",
    "    if K == 1:\n",
    "            return [-(math.pi)**(-(1/4)) * x, math.sqrt(2)/(math.pi)**(1/4) * (1 - x**2)]\n",
    "    return phi1(K-1, x, f)+[2 * K * const * (scipy.special.hermite(K-1, monic=False)(x)) - const * x * (scipy.special.hermite(K, monic=False)(x))]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677951cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(sigma, T, N, M, K, f):\n",
    "    h = T / N\n",
    "    X = np.random.normal(0, 1, M)\n",
    "    gamma = np.zeros((K+1, N+1))\n",
    "    gamma[:,0] = mean( (np.array(H(K, X, f)) * np.exp(-((X ** 2)/2))), axis=1 )\n",
    "    \n",
    "    for i in range(N):\n",
    "        W = np.random.normal(0, 1, M) \n",
    "        X = X + ( np.dot(gamma[:,i], alpha(K, M, X, f)) ) * h + sigma * math.sqrt(h) * W\n",
    "        gamma[:,i+1] = mean( (np.array(H(K, X, f)) * np.exp(-((X ** 2)/2))), axis=1 )\n",
    "    \n",
    "    return X, gamma "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7057b80b",
   "metadata": {},
   "source": [
    "## Gradient Descend Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ff9fa5",
   "metadata": {},
   "source": [
    "### Euler for the simulation of $Z(\\xi , W)$ and $\\left( Z^a(\\tilde{\\xi} , \\tilde{W}), \\partial_{a_{h,j}} Z^a(\\tilde{\\xi} , \\tilde{W}) \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7af779d",
   "metadata": {},
   "source": [
    "We define the two functions that allow us to simulate $Z(\\xi , W)$ and $\\left( Z^a(\\tilde{\\xi} , \\tilde{W}), \\partial_{a_{h,j}} Z^a(\\tilde{\\xi} , \\tilde{W}) \\right)$, i.e. the solutions of the system given by the following differential equations:\n",
    "\n",
    "$$ dZ_t = \\textbf{h} \\left((\\mathcal{L}a)(t)\\right) \\left( \\alpha(t, Z_t)dt + \\beta(t, Z_t)dW_t\\right), \\ \\ \\ Z_0 = \\xi.$$\n",
    "\n",
    "$$ dY^{j,k}_t = g_j(t) \\nabla \\textbf{h}_k \\left((\\mathcal{L}a)(t)\\right) \\left( \\alpha(t, Z_t)dt + \\beta(t, Z_t)dW_t\\right) + \\sum_{i=0}^d Y^{j,k,i}_t  \\textbf{h} \\left((\\mathcal{L}a)(t)\\right) \\left( \\partial_{z_i}\\alpha(t, Z_t)dt + \\partial_{z_i}\\beta(t, Z_t)dW_t\\right), \\ \\ \\ \\ Y^{j,k}_0 = 0,$$\n",
    "\n",
    "for $j = 0, \\cdots , n$ and $k = 1, \\cdots, K$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b13a353",
   "metadata": {},
   "source": [
    "This function is used to create the base of the polynomial space. It takes in input the dimension $n$, the time $t$ in which the base vectors are to be calculated and the base type chosen. Returns a $n+1$ dimensional vector representing the base items calculated in $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87335224",
   "metadata": {},
   "source": [
    "* canonical base:   $g_i(t):= t^i$ with equidistant knots;\n",
    "* Lagrange's base: $g_i(t):=\\prod_{j \\leq n \\ and  \\ j\\neq n} \\left( \\frac{t - t_j}{t_i - t_j} \\right) $ with Chebyshev's knots: $\\frac{a+b}{2} + \\frac{b-a}{2} cos \\left( \\frac{2k + 1}{2n +2} \\pi \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded2911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base(T, N, n, K, f, tipo):\n",
    "    g = np.ones(n+1)\n",
    "    cc = np.linspace(0, T, N+1)\n",
    "    a = np.zeros((K+1, n+1)) \n",
    "    X = np.random.normal(0, 1, 1)\n",
    "    \n",
    "    if tipo == 'canonical':\n",
    "        g = np.array([ cc ** i for i in range(n+1)]) \n",
    "        \n",
    "        a[0,0] = (math.sqrt(2) * math.pi)**(-(1/4))\n",
    "        \n",
    "        return a, g\n",
    "    \n",
    "    elif tipo == 'lagrange':\n",
    "        l = [(0 + T)/2 + (T - 0)/2 * np.cos(((2 * i + 1)/ (2 * n + 2)) * math.pi) for i in range(n+1)]\n",
    "        \n",
    "        g = np.array([math.prod([((cc - l[j]) / (l[i] - l[j])) for j in range(n+1) if j!=i]) for i in range(n+1)])\n",
    "        \n",
    "        a[0,:] = (math.sqrt(2) * math.pi)**(-(1/4))\n",
    "        \n",
    "        return a, g \n",
    "        \n",
    "    \n",
    "    else:\n",
    "        return 'err'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2808e4bc",
   "metadata": {},
   "source": [
    "In this simplified algorithm the two maps $\\textbf{h}$ and $ H $ are respectively the identity function and the null function. Considering the values of the coefficient functions for the convolution type MV-SDE, we have that the equations are:\n",
    "\n",
    "$$ \\mathrm{d} Z_t = \\Big( (\\mathcal{L}a)_0(t)\\alpha_0(Z_t) + \\cdots + (\\mathcal{L}a)_K(t)\\alpha_K(Z_t) \\Big) \\mathrm{d} t + \\sigma \\mathrm{d} W_t, \\ \\ \\ Z_0 = \\mathcal{N}_{(0,1)}. $$ \n",
    "\n",
    "$$ (\\mathcal{L}a)_{l=0, \\cdots , K}(t) = \\sum^{n}_{i=1} a_{l,i} \\prod_{\\substack{ 1\\leq j \\leq n \\\\ i\\neq j}} \\frac{t-t_j}{t_i - t_j}. $$\n",
    "\n",
    "The gradient processes $Y^{i, l}_t:= \\partial_{a_{l,i}}Z_t, \\mbox{ with } l=0, \\cdots, K \\mbox{ and } i = 1, \\ldots, n,$ are given as:\n",
    "\n",
    "$$ \\begin{align}\n",
    "\\textrm{d}Y^{i,0}_t &= \\bigl( \\prod_{\\substack{ 1\\leq j \\leq n \\\\ i\\neq j}} \\frac{t-t_j}{t_i - t_j} \\alpha_0(Z_t) + (\\mathcal{L}a)_0(t) \\alpha^\\prime_0(Z_t)  Y^{i,0}_t + \\cdots + (\\mathcal{L}a)_K(t) \\alpha^\\prime_K(Z_t)  Y^{i,0}_t\\bigr) \\textrm{d} t, \\quad Y^{i,0}_0 = 0,\\\\\n",
    "\\vdots \\\\\n",
    "\\textrm{d}Y^{i,K}_t &= \\bigl( \\prod_{\\substack{ 1\\leq j \\leq n \\\\ i\\neq j}} \\frac{t-t_j}{t_i - t_j} \\alpha_K(Z_t) + (\\mathcal{L}a)_0(t) \\alpha^\\prime_0(Z_t)  Y^{i,K}_t + \\cdots + (\\mathcal{L}a)_K(t) \\alpha^\\prime_K(Z_t)  Y^{i,K}_t\\bigr) \\textrm{d} t, \\quad Y^{i,K}_0 = 0,\\\\\n",
    "\\end{align} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca80ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler(a, sigma, n, N, M, h, K, g, f):\n",
    "    \n",
    "    Z = np.zeros((N+1, M))\n",
    "    Ztilde = np.zeros((N+1, M))\n",
    "    Ytilde = np.zeros((n+1, K+1, N+1, M))\n",
    "    Tensor = np.zeros((M, K+1, n+1))\n",
    "    \n",
    "\n",
    "    Z[0,:] = np.random.normal(0, 1, M) \n",
    "    Ztilde[0,:] = np.random.normal(0, 1, M)\n",
    " \n",
    "    \n",
    "    for i in range(N):\n",
    "        c = np.dot(a, g[:,i])\n",
    "        Tensor[:,:,:] = np.array(g[:,i])\n",
    "        alphaZtilde = alpha(K, M, Ztilde[i], f)\n",
    "        alpha1Ztilde = alpha1(K, M, Ztilde[i], f)\n",
    "        \n",
    "        W = np.random.normal(0, 1, (2, M)) \n",
    "    \n",
    "        Z[i+1] = Z[i] + ( np.dot(c, alpha(K, M, Z[i], f)) ) * h + sigma * math.sqrt(h) * W[0]\n",
    "        \n",
    "        Ytilde[:,:,i+1,:] = Ytilde[:,:,i,:] + \\\n",
    "            ( Tensor.transpose() * ( alphaZtilde * np.ones((n+1, K+1, M)) ) + \\\n",
    "             ( (K+1) * mean( ( c * np.ones((M, 1)) ).transpose() * alpha1Ztilde, axis=0 ) ) * Ytilde[:,:,i,:] ) * h\n",
    "        \n",
    "        Ztilde[i+1] = Ztilde[i] + ( np.dot(c, alphaZtilde) ) * h + sigma * math.sqrt(h) * W[1]\n",
    "        \n",
    "    \n",
    "    return Z, Ztilde, Ytilde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7bac12",
   "metadata": {},
   "source": [
    "### Descent Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da5da8f",
   "metadata": {},
   "source": [
    "In this section are the two most important functions of the code. The first is used to calculate the realisation of the gradient for stochastic descent, i.e. the function $v$. In general, the writing of $v$, component by component, is as follows:\n",
    "\n",
    "$$v_{j,k}(a; \\xi, W; \\tilde{\\xi}, \\tilde{W}) = 2 \\int_0^T \\langle \\varphi (Z^a_t(\\xi,W)) - \\textbf{h} ((\\mathcal{L}a)(t)), \\nabla_x \\varphi (Z^a_t(\\tilde{\\xi}, \\tilde{W})) Y_t^{a;j,k}(\\tilde{\\xi}, \\tilde{W}) - \\partial_{a_{j,k}}\\textbf{h}((\\mathcal{L}a)(t))\\rangle dt, $$ \n",
    "with $j = 0, \\cdots , n$ e $k = 0, \\cdots, K$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de3e8a5",
   "metadata": {},
   "source": [
    "As in the previous cases, we write this e quation in the specific case of our algorithm. In particular, we have divided the time interval into N steps and therefore approximate the integral with a sum.\n",
    "\n",
    "$$ v_{j,0}(a; W; \\tilde{W}) = 2 h \\sum_{t=0}^{N} \\left[ \\left( \\varphi_0(Z^a_t(W)) - (\\mathcal{L}a)_0(t) \\right) \\left( \\varphi'_0(Z^a_t(\\tilde{W})) Y^{j,0}_t(\\tilde{W}) - g_j(t)\\right) + \\cdots + \\left( \\varphi_K(Z^a_t(W)) - (\\mathcal{L}a)_K(t) \\right)  \\varphi'_K(Z^a_t(\\tilde{W})) Y^{j,0}_t(\\tilde{W}) \\right], $$\n",
    "$$ \\vdots \\\\ $$\n",
    "$$ v_{j,K}(a; W; \\tilde{W}) = 2 h \\sum_{t=0}^{N} \\left[ \\left( \\varphi_0(Z^a_t(W)) - (\\mathcal{L}a)_0(t) \\right) \\varphi'_0(Z^a_t(\\tilde{W})) Y^{j,K}_t(\\tilde{W}) + \\cdots + \\left( \\varphi_K(Z^a_t(W)) - (\\mathcal{L}a)_K(t) \\right) \\left( \\varphi'_K(Z^a_t(\\tilde{W})) Y^{j,K}_t(\\tilde{W}) - g_j(t) \\right) \\right], $$\n",
    "\n",
    "with $j = 0, \\cdots, n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e9a7f",
   "metadata": {},
   "source": [
    "We highlight that before returning the value $v$ this fuction averages it. This is in the case if $M>1$, where we exploit multiple simulations of the Brownian to get a better estimate of $v$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab05a0c8",
   "metadata": {},
   "source": [
    "$$ err = \\frac{ \\sum_{k,j} \\left( (\\gamma_{MC})_k(t_j)-(\\gamma_{SGD})_k(t_j) \\right)^2 }{\\sum_k,j (\\gamma_{MC})^2_k(t_j)}  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecde5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(a_0, n, r0, rho, sigma, N, M, K, eps, h, g, gamma, f, l):\n",
    "    \n",
    "    a = a_0 \n",
    "    norm = LA.norm(gamma)\n",
    "    \n",
    "    for m in range(50000):\n",
    "        \n",
    "        if (m % l == 0):\n",
    "            if (LA.norm( np.dot(a,g) - gamma ) / norm < eps) :\n",
    "                break\n",
    "            \n",
    "        eta = r0 / ((m + 1) ** rho) \n",
    "        \n",
    "        Z, Ztilde, Ytilde = euler(a, sigma, n, N, M, h, K, g, f) \n",
    "        \n",
    "        primo = ( np.array(H(K, Z, f)) * np.exp(-((Z ** 2)/2)) ) - ( np.array([(np.dot(a[i], g) * np.ones((M,1))).transpose() for i in range(K+1)]) )\n",
    "        secondo = np.zeros((K+1, K+1, N+1, M))\n",
    "        Tensor = np.zeros((M, N+1, K+1, K+1))\n",
    "        Tensor[:,:,:,:] = np.eye(K+1)\n",
    "        Tensor = Tensor.transpose()\n",
    "        v = np.zeros((K+1, n+1))\n",
    "        \n",
    "        for j in range(n+1):\n",
    "            secondo[:,:,:,:] = ( np.array(phi1(K, Ztilde, f)) * np.exp(-((Ztilde ** 2)/2)) ) \n",
    "            secondo = secondo * Ytilde[j,:,:,:]\n",
    "            terzo = np.swapaxes(secondo,0,1) - (g[j,:] * np.ones((M, 1))).transpose() * Tensor\n",
    "\n",
    "            v[:,j] =  mean( 2 * h * (N+1) * mean ( (K+1) * mean(primo * terzo, axis = 1), axis = 1 ) , axis = 1)\n",
    "\n",
    "        a = a - eta * v\n",
    "        \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e00b41",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c04ab48",
   "metadata": {},
   "source": [
    "Let us conclude by showing the main that calls the functions defined above. Let us recall what the values we will give as input to the functions we will call up correspond to:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40527834",
   "metadata": {},
   "source": [
    "* T : final istant,\n",
    "* K : number of gamma function in the SDE\n",
    "* $M_1$ : number of simulation for the MC,\n",
    "* $N_1$ : time stes for the MC,\n",
    "* N : time steps for the SGD,\n",
    "* $\\sigma$: constant diffusion,\n",
    "* h : time step,\n",
    "* $X_0$ : initial data,\n",
    "* nnn : dimension of the polynomial space,\n",
    "* $a_0$ : initial value of the SGD method vector,\n",
    "* $r_0$ e $\\rho$: learning rates constants. Must hold that: $r_0 \\in (0, +\\infty)$ and $\\frac{1}{2} < \\rho \\leq 1$,\n",
    "* m: number of iteration for the SGD method,\n",
    "* M: Mini Batch between SGD and GD,\n",
    "* $\\epsilon$: 1% relative error tolerance,\n",
    "* repetition: number of identical simulations we run for each parameter combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "479ab0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done K = 15\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # variable parameters\n",
    "    \n",
    "    T = 1\n",
    "    N1 = 100\n",
    "    N = 100\n",
    "    KK = [15]   # 1, 5 ,10, 20\n",
    "    sigma = 0.1\n",
    "    n = 3 \n",
    "    M1 = 100000\n",
    "    M = [100] #[1, 10, 100, 1000]   # 10, 100, 1000, 10000\n",
    "    h = T / N  \n",
    "    l = [10, 10, 10, 1]\n",
    "    repetition = 10 \n",
    "    r0 = [5, 4, 3, 2]# [1, 2, 5]  \n",
    "    rho = [0.9, 0.95, 0.99] #[0.8, 0.9, 0.95]\n",
    "    eps = 0.01\n",
    "    \n",
    "\n",
    "    # Euler - Monte Carlo\n",
    "    \n",
    "    # start = time.process_time()   # the stopwatch starts\n",
    "    # X, gamma = monte_carlo(sigma, T, N1, M1, K, f)\n",
    "    # end = time.process_time()   # the stopwatch stops\n",
    "\n",
    "    # print(\"Euler - Monte Carlo execution time: \", end - start)\n",
    "    # print(\" \")\n",
    "    \n",
    "    gamma = np.load('gammaMC.npy')\n",
    "    \n",
    "    \n",
    "            \n",
    "    for K in KK:\n",
    "        \n",
    "        # Gradient Descent\n",
    "        \n",
    "        f = factorial(K)\n",
    "        a_0, g = base(T, N, n, K, f, 'lagrange')\n",
    "        \n",
    "        m = np.zeros((len(rho), len(r0)*3+1))\n",
    "        m[:,0] = rho\n",
    "        \n",
    "        with open(\"times K = \"+str(K)+\".txt\", \"w\") as F:\n",
    "            \n",
    "            for p in range(len(M)):\n",
    "                F.write(\"Number of iterations to achieve convergence with M = \"+str(M[p])+\" :\")\n",
    "                F.write(\"\\n\")\n",
    "                F.write(\"\\n\")\n",
    "\n",
    "                for i in range(len(r0)):\n",
    "                    for j in range(len(rho)):\n",
    "\n",
    "                        start = time.process_time()   # the stopwatch starts\n",
    "                        mm = [stochastic_gradient_descent(a_0, n, r0[i], rho[j], sigma, N, M[p], K, eps, h, g, gamma[0:K+1], f, l[p]) for u in range(repetition)] \n",
    "                        m[j,3*i+1:3*i+4] = [min(mm), max(mm), mean(mm)]\n",
    "                        end = time.process_time()   # the stopwatch stops \n",
    "\n",
    "                        F.write(\"Execution time with r0=\"+str(r0[i])+\" and rho=\"+str(rho[j])+\": \"+ str((end - start)/repetition))\n",
    "                        F.write(\"\\n\")\n",
    "\n",
    "                F.write(\"\\n\")\n",
    "                F.write(tabulate(m[:,:], headers=[\" rho \\ r0\", \"5 (min)\", \"5 (max)\", \"5 (average)\", \"10 (min)\", \"10 (max)\", \"10 (average)\"]))\n",
    "                F.write(\"\\n\")\n",
    "                F.write(\"\\n\")\n",
    "        \n",
    "        print(\"done K = \"+str(K))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42317ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----  ---  ----  ---  ---  ----  ---  ---  ---  ---  ---  ----  ---\n",
      "0.9   440  1170  645  320   750  517  210  820  482  140   850  405\n",
      "0.95  210   840  508  280   780  484  150  810  433  170  1040  457\n",
      "0.99  200   850  521  240  1220  601  260  760  391  240  1230  540\n",
      "----  ---  ----  ---  ---  ----  ---  ---  ---  ---  ---  ----  ---\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aa9ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9876a44e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
